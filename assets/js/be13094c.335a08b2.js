"use strict";(globalThis.webpackChunkdocusaurus_poc=globalThis.webpackChunkdocusaurus_poc||[]).push([[3694],{4821:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"devops/observability/prometheus-grafana","title":"\ud83d\udcc8 Prometheus & Grafana - Monitoring Complet","description":"Stack de monitoring compl\xe8te pour Java, Drupal, Angular et infrastructure.","source":"@site/docs/devops/observability/prometheus-grafana.md","sourceDirName":"devops/observability","slug":"/devops/observability/prometheus-grafana","permalink":"/docs/devops/observability/prometheus-grafana","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/devops/observability/prometheus-grafana.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docs","previous":{"title":"\ud83d\udd37 Pipeline Drupal - GitLab CI","permalink":"/docs/devops/cicd/pipelines-drupal"},"next":{"title":"ZIPKIN","permalink":"/docs/devops/observability/zipkin"}}');var r=a(4848),s=a(8453);const o={sidebar_position:1},i="\ud83d\udcc8 Prometheus & Grafana - Monitoring Complet",l={},c=[{value:"\ud83c\udfaf Architecture de monitoring",id:"-architecture-de-monitoring",level:2},{value:"\ud83d\ude80 Installation Stack compl\xe8te",id:"-installation-stack-compl\xe8te",level:2},{value:"Docker Compose - Stack de monitoring",id:"docker-compose---stack-de-monitoring",level:3},{value:"\u2699\ufe0f Configuration Prometheus",id:"\ufe0f-configuration-prometheus",level:2},{value:"\ud83d\udea8 Alerting Rules",id:"-alerting-rules",level:2},{value:"\ud83d\udce7 Configuration Alertmanager",id:"-configuration-alertmanager",level:2},{value:"\ud83d\udcca Dashboards Grafana",id:"-dashboards-grafana",level:2},{value:"Dashboard Java/Spring Boot",id:"dashboard-javaspring-boot",level:3},{value:"Dashboard Drupal",id:"dashboard-drupal",level:3},{value:"Dashboard Angular",id:"dashboard-angular",level:3}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",mermaid:"mermaid",p:"p",pre:"pre",...(0,s.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"-prometheus--grafana---monitoring-complet",children:"\ud83d\udcc8 Prometheus & Grafana - Monitoring Complet"})}),"\n",(0,r.jsx)(e.p,{children:"Stack de monitoring compl\xe8te pour Java, Drupal, Angular et infrastructure."}),"\n",(0,r.jsx)(e.h2,{id:"-architecture-de-monitoring",children:"\ud83c\udfaf Architecture de monitoring"}),"\n",(0,r.jsx)(e.mermaid,{value:'graph TB\n    subgraph "Applications"\n        JAVA[\u2615 Spring Boot<br/>Micrometer]\n        DRUPAL[\ud83d\udd37 Drupal<br/>PHP-FPM Exporter]\n        ANGULAR[\ud83c\udd70\ufe0f Angular<br/>Real User Monitoring]\n        NGINX[\ud83c\udf10 Nginx<br/>Exporter]\n    end\n    \n    subgraph "Infrastructure"\n        NODE[\ud83d\udda5\ufe0f Node Exporter]\n        CADVISOR[\ud83d\udc33 cAdvisor<br/>Containers]\n        KUBE[\u2638\ufe0f Kube State Metrics]\n        POSTGRES[\ud83d\udc18 Postgres Exporter]\n        REDIS[\ud83d\udd34 Redis Exporter]\n    end\n    \n    subgraph "Collecte"\n        PROM[\ud83d\udcca Prometheus]\n        LOKI[\ud83d\udcdd Loki<br/>Logs]\n        TEMPO[\ud83d\udd0d Tempo<br/>Traces]\n    end\n    \n    subgraph "Visualisation"\n        GRAFANA[\ud83d\udcca Grafana]\n        DASH1[Dashboard Java]\n        DASH2[Dashboard Drupal]\n        DASH3[Dashboard Angular]\n        DASH4[Dashboard Infra]\n    end\n    \n    subgraph "Alerting"\n        ALERTMANAGER[\ud83d\udea8 Alertmanager]\n        SLACK[\ud83d\udcac Slack]\n        PAGERDUTY[\ud83d\udcdf PagerDuty]\n        EMAIL[\ud83d\udce7 Email]\n    end\n    \n    JAVA --\x3e PROM\n    DRUPAL --\x3e PROM\n    ANGULAR --\x3e PROM\n    NGINX --\x3e PROM\n    NODE --\x3e PROM\n    CADVISOR --\x3e PROM\n    KUBE --\x3e PROM\n    POSTGRES --\x3e PROM\n    REDIS --\x3e PROM\n    \n    JAVA --\x3e LOKI\n    DRUPAL --\x3e LOKI\n    NGINX --\x3e LOKI\n    \n    JAVA --\x3e TEMPO\n    DRUPAL --\x3e TEMPO\n    ANGULAR --\x3e TEMPO\n    \n    PROM --\x3e GRAFANA\n    LOKI --\x3e GRAFANA\n    TEMPO --\x3e GRAFANA\n    \n    GRAFANA --\x3e DASH1\n    GRAFANA --\x3e DASH2\n    GRAFANA --\x3e DASH3\n    GRAFANA --\x3e DASH4\n    \n    PROM --\x3e ALERTMANAGER\n    ALERTMANAGER --\x3e SLACK\n    ALERTMANAGER --\x3e PAGERDUTY\n    ALERTMANAGER --\x3e EMAIL'}),"\n",(0,r.jsx)(e.h2,{id:"-installation-stack-compl\xe8te",children:"\ud83d\ude80 Installation Stack compl\xe8te"}),"\n",(0,r.jsx)(e.h3,{id:"docker-compose---stack-de-monitoring",children:"Docker Compose - Stack de monitoring"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-yaml",metastring:'title="docker-compose-monitoring.yml"',children:"version: '3.8'\n\nnetworks:\n  monitoring:\n    driver: bridge\n\nvolumes:\n  prometheus_data:\n  grafana_data:\n  loki_data:\n  tempo_data:\n\nservices:\n  # Prometheus - M\xe9triques\n  prometheus:\n    image: prom/prometheus:latest\n    container_name: prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--storage.tsdb.retention.time=30d'\n      - '--web.console.libraries=/etc/prometheus/console_libraries'\n      - '--web.console.templates=/etc/prometheus/consoles'\n      - '--web.enable-lifecycle'\n      - '--web.enable-admin-api'\n    ports:\n      - \"9090:9090\"\n    volumes:\n      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml\n      - ./prometheus/alerts:/etc/prometheus/alerts\n      - prometheus_data:/prometheus\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # Grafana - Visualisation\n  grafana:\n    image: grafana/grafana:latest\n    container_name: grafana\n    ports:\n      - \"3000:3000\"\n    environment:\n      - GF_SECURITY_ADMIN_USER=admin\n      - GF_SECURITY_ADMIN_PASSWORD=admin123\n      - GF_INSTALL_PLUGINS=redis-datasource,grafana-piechart-panel\n      - GF_AUTH_ANONYMOUS_ENABLED=false\n      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/etc/grafana/provisioning/dashboards/home.json\n    volumes:\n      - grafana_data:/var/lib/grafana\n      - ./grafana/provisioning:/etc/grafana/provisioning\n      - ./grafana/dashboards:/etc/grafana/dashboards\n    networks:\n      - monitoring\n    restart: unless-stopped\n    depends_on:\n      - prometheus\n\n  # Loki - Logs\n  loki:\n    image: grafana/loki:latest\n    container_name: loki\n    ports:\n      - \"3100:3100\"\n    command: -config.file=/etc/loki/local-config.yaml\n    volumes:\n      - ./loki/loki-config.yml:/etc/loki/local-config.yaml\n      - loki_data:/loki\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # Promtail - Collecteur de logs\n  promtail:\n    image: grafana/promtail:latest\n    container_name: promtail\n    volumes:\n      - /var/log:/var/log\n      - /var/lib/docker/containers:/var/lib/docker/containers\n      - ./promtail/promtail-config.yml:/etc/promtail/config.yml\n    command: -config.file=/etc/promtail/config.yml\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # Tempo - Traces\n  tempo:\n    image: grafana/tempo:latest\n    container_name: tempo\n    command: [ \"-config.file=/etc/tempo.yaml\" ]\n    volumes:\n      - ./tempo/tempo.yml:/etc/tempo.yaml\n      - tempo_data:/tmp/tempo\n    ports:\n      - \"3200:3200\"   # tempo\n      - \"4317:4317\"   # otlp grpc\n      - \"4318:4318\"   # otlp http\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # Alertmanager - Gestion des alertes\n  alertmanager:\n    image: prom/alertmanager:latest\n    container_name: alertmanager\n    ports:\n      - \"9093:9093\"\n    volumes:\n      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml\n    command:\n      - '--config.file=/etc/alertmanager/alertmanager.yml'\n      - '--storage.path=/alertmanager'\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # Node Exporter - M\xe9triques syst\xe8me\n  node-exporter:\n    image: prom/node-exporter:latest\n    container_name: node-exporter\n    command:\n      - '--path.procfs=/host/proc'\n      - '--path.rootfs=/rootfs'\n      - '--path.sysfs=/host/sys'\n      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'\n    ports:\n      - \"9100:9100\"\n    volumes:\n      - /proc:/host/proc:ro\n      - /sys:/host/sys:ro\n      - /:/rootfs:ro\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # cAdvisor - M\xe9triques containers\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:latest\n    container_name: cadvisor\n    ports:\n      - \"8080:8080\"\n    volumes:\n      - /:/rootfs:ro\n      - /var/run:/var/run:ro\n      - /sys:/sys:ro\n      - /var/lib/docker:/var/lib/docker:ro\n      - /dev/disk:/dev/disk:ro\n    privileged: true\n    devices:\n      - /dev/kmsg\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # Redis Exporter\n  redis-exporter:\n    image: oliver006/redis_exporter:latest\n    container_name: redis-exporter\n    ports:\n      - \"9121:9121\"\n    environment:\n      - REDIS_ADDR=redis:6379\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # Postgres Exporter\n  postgres-exporter:\n    image: prometheuscommunity/postgres-exporter:latest\n    container_name: postgres-exporter\n    ports:\n      - \"9187:9187\"\n    environment:\n      - DATA_SOURCE_NAME=postgresql://user:password@postgres:5432/dbname?sslmode=disable\n    networks:\n      - monitoring\n    restart: unless-stopped\n\n  # Nginx Exporter\n  nginx-exporter:\n    image: nginx/nginx-prometheus-exporter:latest\n    container_name: nginx-exporter\n    ports:\n      - \"9113:9113\"\n    command:\n      - -nginx.scrape-uri=http://nginx:8080/stub_status\n    networks:\n      - monitoring\n    restart: unless-stopped\n"})}),"\n",(0,r.jsx)(e.h2,{id:"\ufe0f-configuration-prometheus",children:"\u2699\ufe0f Configuration Prometheus"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-yaml",metastring:'title="prometheus/prometheus.yml"',children:"global:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n  external_labels:\n    cluster: 'production'\n    region: 'eu-west-1'\n\n# R\xe8gles d'alerting\nrule_files:\n  - '/etc/prometheus/alerts/*.yml'\n\n# Configuration Alertmanager\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n            - 'alertmanager:9093'\n\n# Scrape configs\nscrape_configs:\n  # Prometheus lui-m\xeame\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['localhost:9090']\n\n  # Applications Java (Spring Boot Actuator)\n  - job_name: 'spring-boot-apps'\n    metrics_path: '/actuator/prometheus'\n    static_configs:\n      - targets:\n          - 'java-app-1:8080'\n          - 'java-app-2:8080'\n    relabel_configs:\n      - source_labels: [__address__]\n        target_label: instance\n        regex: '([^:]+).*'\n        replacement: '${1}'\n\n  # Drupal (PHP-FPM Exporter)\n  - job_name: 'drupal-apps'\n    static_configs:\n      - targets:\n          - 'phpfpm-exporter:9253'\n\n  # Angular (via Nginx)\n  - job_name: 'angular-apps'\n    static_configs:\n      - targets:\n          - 'nginx-exporter:9113'\n\n  # Infrastructure\n  - job_name: 'node-exporter'\n    static_configs:\n      - targets:\n          - 'node-exporter:9100'\n\n  - job_name: 'cadvisor'\n    static_configs:\n      - targets:\n          - 'cadvisor:8080'\n\n  # Bases de donn\xe9es\n  - job_name: 'postgres'\n    static_configs:\n      - targets:\n          - 'postgres-exporter:9187'\n\n  - job_name: 'redis'\n    static_configs:\n      - targets:\n          - 'redis-exporter:9121'\n\n  # Kubernetes (si applicable)\n  - job_name: 'kubernetes-apiservers'\n    kubernetes_sd_configs:\n      - role: endpoints\n    scheme: https\n    tls_config:\n      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt\n    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token\n    relabel_configs:\n      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]\n        action: keep\n        regex: default;kubernetes;https\n\n  - job_name: 'kubernetes-pods'\n    kubernetes_sd_configs:\n      - role: pod\n    relabel_configs:\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n        action: keep\n        regex: true\n      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]\n        action: replace\n        target_label: __metrics_path__\n        regex: (.+)\n      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]\n        action: replace\n        regex: ([^:]+)(?::\\d+)?;(\\d+)\n        replacement: $1:$2\n        target_label: __address__\n\n# Remote write (optionnel - pour Thanos ou Cortex)\nremote_write:\n  - url: 'http://thanos-receive:19291/api/v1/receive'\n    queue_config:\n      capacity: 10000\n      max_shards: 50\n      min_shards: 1\n"})}),"\n",(0,r.jsx)(e.h2,{id:"-alerting-rules",children:"\ud83d\udea8 Alerting Rules"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-yaml",metastring:'title="prometheus/alerts/application-alerts.yml"',children:'groups:\n  - name: application_alerts\n    interval: 30s\n    rules:\n      # Java Application - High Error Rate\n      - alert: JavaHighErrorRate\n        expr: |\n          rate(http_server_requests_seconds_count{status=~"5.."}[5m]) \n          / \n          rate(http_server_requests_seconds_count[5m]) \n          > 0.05\n        for: 5m\n        labels:\n          severity: critical\n          team: backend\n        annotations:\n          summary: "High error rate on {{ $labels.instance }}"\n          description: "Error rate is {{ $value | humanizePercentage }} (threshold: 5%)"\n\n      # Java Application - High Latency\n      - alert: JavaHighLatency\n        expr: |\n          histogram_quantile(0.95, \n            rate(http_server_requests_seconds_bucket[5m])\n          ) > 1\n        for: 5m\n        labels:\n          severity: warning\n          team: backend\n        annotations:\n          summary: "High latency on {{ $labels.instance }}"\n          description: "95th percentile latency is {{ $value }}s"\n\n      # Java Application - Memory Usage\n      - alert: JavaHighMemoryUsage\n        expr: |\n          (jvm_memory_used_bytes{area="heap"} \n          / \n          jvm_memory_max_bytes{area="heap"}) \n          > 0.90\n        for: 5m\n        labels:\n          severity: warning\n          team: backend\n        annotations:\n          summary: "High memory usage on {{ $labels.instance }}"\n          description: "Heap memory usage is {{ $value | humanizePercentage }}"\n\n      # Java Application - High GC Time\n      - alert: JavaHighGCTime\n        expr: |\n          rate(jvm_gc_pause_seconds_sum[5m]) \n          / \n          rate(jvm_gc_pause_seconds_count[5m]) \n          > 0.1\n        for: 5m\n        labels:\n          severity: warning\n          team: backend\n        annotations:\n          summary: "High GC time on {{ $labels.instance }}"\n          description: "Average GC pause is {{ $value }}s"\n\n      # Drupal - PHP-FPM High Pool Usage\n      - alert: PHPFPMHighPoolUsage\n        expr: |\n          (phpfpm_active_processes \n          / \n          phpfpm_max_children) \n          > 0.80\n        for: 5m\n        labels:\n          severity: warning\n          team: drupal\n        annotations:\n          summary: "High PHP-FPM pool usage"\n          description: "Pool usage is {{ $value | humanizePercentage }}"\n\n      # Drupal - Database Slow Queries\n      - alert: DrupalSlowQueries\n        expr: |\n          rate(mysql_global_status_slow_queries[5m]) > 10\n        for: 5m\n        labels:\n          severity: warning\n          team: drupal\n        annotations:\n          summary: "High number of slow queries"\n          description: "{{ $value }} slow queries per second"\n\n      # Angular - High Client Errors\n      - alert: AngularHighClientErrors\n        expr: |\n          rate(nginx_http_requests_total{status=~"4.."}[5m]) > 100\n        for: 5m\n        labels:\n          severity: warning\n          team: frontend\n        annotations:\n          summary: "High client error rate"\n          description: "{{ $value }} 4xx errors per second"\n'})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-yaml",metastring:'title="prometheus/alerts/infrastructure-alerts.yml"',children:'groups:\n  - name: infrastructure_alerts\n    interval: 30s\n    rules:\n      # Node - High CPU\n      - alert: HostHighCPU\n        expr: |\n          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n        for: 5m\n        labels:\n          severity: warning\n          team: devops\n        annotations:\n          summary: "High CPU usage on {{ $labels.instance }}"\n          description: "CPU usage is {{ $value }}%"\n\n      # Node - High Memory\n      - alert: HostHighMemory\n        expr: |\n          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90\n        for: 5m\n        labels:\n          severity: critical\n          team: devops\n        annotations:\n          summary: "High memory usage on {{ $labels.instance }}"\n          description: "Memory usage is {{ $value }}%"\n\n      # Node - Disk Space\n      - alert: HostLowDiskSpace\n        expr: |\n          (node_filesystem_avail_bytes{mountpoint="/"} \n          / \n          node_filesystem_size_bytes{mountpoint="/"}) \n          * 100 < 10\n        for: 5m\n        labels:\n          severity: critical\n          team: devops\n        annotations:\n          summary: "Low disk space on {{ $labels.instance }}"\n          description: "Only {{ $value }}% disk space remaining"\n\n      # Container - High CPU\n      - alert: ContainerHighCPU\n        expr: |\n          rate(container_cpu_usage_seconds_total{container!=""}[5m]) * 100 > 80\n        for: 5m\n        labels:\n          severity: warning\n          team: devops\n        annotations:\n          summary: "High CPU on container {{ $labels.container }}"\n          description: "CPU usage is {{ $value }}%"\n\n      # Container - OOM Killed\n      - alert: ContainerOOMKilled\n        expr: |\n          increase(container_oom_events_total[5m]) > 0\n        labels:\n          severity: critical\n          team: devops\n        annotations:\n          summary: "Container {{ $labels.container }} OOM killed"\n          description: "Container was killed due to out of memory"\n\n      # Database - High Connections\n      - alert: PostgresHighConnections\n        expr: |\n          (pg_stat_database_numbackends \n          / \n          pg_settings_max_connections) \n          > 0.80\n        for: 5m\n        labels:\n          severity: warning\n          team: database\n        annotations:\n          summary: "High Postgres connections"\n          description: "{{ $value | humanizePercentage }} of max connections used"\n\n      # Redis - High Memory\n      - alert: RedisHighMemory\n        expr: |\n          (redis_memory_used_bytes \n          / \n          redis_memory_max_bytes) \n          > 0.90\n        for: 5m\n        labels:\n          severity: warning\n          team: cache\n        annotations:\n          summary: "High Redis memory usage"\n          description: "Memory usage is {{ $value | humanizePercentage }}"\n'})}),"\n",(0,r.jsx)(e.h2,{id:"-configuration-alertmanager",children:"\ud83d\udce7 Configuration Alertmanager"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-yaml",metastring:'title="alertmanager/alertmanager.yml"',children:"global:\n  resolve_timeout: 5m\n  slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'\n\n# Templates\ntemplates:\n  - '/etc/alertmanager/templates/*.tmpl'\n\n# Routes\nroute:\n  group_by: ['alertname', 'cluster', 'service']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 12h\n  receiver: 'default'\n  \n  routes:\n    # Critical alerts -> PagerDuty\n    - match:\n        severity: critical\n      receiver: 'pagerduty'\n      continue: true\n    \n    # Critical alerts -> Slack\n    - match:\n        severity: critical\n      receiver: 'slack-critical'\n    \n    # Warning alerts -> Slack\n    - match:\n        severity: warning\n      receiver: 'slack-warning'\n    \n    # Team-specific routes\n    - match:\n        team: backend\n      receiver: 'slack-backend'\n    \n    - match:\n        team: frontend\n      receiver: 'slack-frontend'\n    \n    - match:\n        team: drupal\n      receiver: 'slack-drupal'\n\n# Inhibition rules\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'instance']\n\n# Receivers\nreceivers:\n  - name: 'default'\n    email_configs:\n      - to: 'devops@example.com'\n        send_resolved: true\n\n  - name: 'pagerduty'\n    pagerduty_configs:\n      - service_key: 'YOUR_PAGERDUTY_SERVICE_KEY'\n        description: '{{ .GroupLabels.alertname }}'\n\n  - name: 'slack-critical'\n    slack_configs:\n      - channel: '#alerts-critical'\n        title: '\ud83d\udea8 CRITICAL ALERT'\n        text: >-\n          {{ range .Alerts }}\n            *Alert:* {{ .Labels.alertname }}\n            *Summary:* {{ .Annotations.summary }}\n            *Description:* {{ .Annotations.description }}\n            *Severity:* {{ .Labels.severity }}\n          {{ end }}\n        send_resolved: true\n\n  - name: 'slack-warning'\n    slack_configs:\n      - channel: '#alerts-warning'\n        title: '\u26a0\ufe0f WARNING ALERT'\n        text: >-\n          {{ range .Alerts }}\n            *Alert:* {{ .Labels.alertname }}\n            *Summary:* {{ .Annotations.summary }}\n          {{ end }}\n\n  - name: 'slack-backend'\n    slack_configs:\n      - channel: '#team-backend'\n        title: '\u2615 Backend Alert'\n\n  - name: 'slack-frontend'\n    slack_configs:\n      - channel: '#team-frontend'\n        title: '\ud83c\udd70\ufe0f Frontend Alert'\n\n  - name: 'slack-drupal'\n    slack_configs:\n      - channel: '#team-drupal'\n        title: '\ud83d\udd37 Drupal Alert'\n"})}),"\n",(0,r.jsx)(e.h2,{id:"-dashboards-grafana",children:"\ud83d\udcca Dashboards Grafana"}),"\n",(0,r.jsx)(e.h3,{id:"dashboard-javaspring-boot",children:"Dashboard Java/Spring Boot"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-json",metastring:'title="grafana/dashboards/java-spring-boot.json"',children:'{\n  "dashboard": {\n    "title": "Java Spring Boot Monitoring",\n    "panels": [\n      {\n        "title": "Request Rate",\n        "targets": [\n          {\n            "expr": "rate(http_server_requests_seconds_count[5m])"\n          }\n        ]\n      },\n      {\n        "title": "Error Rate",\n        "targets": [\n          {\n            "expr": "rate(http_server_requests_seconds_count{status=~\\"5..\\"}[5m])"\n          }\n        ]\n      },\n      {\n        "title": "Response Time (p95)",\n        "targets": [\n          {\n            "expr": "histogram_quantile(0.95, rate(http_server_requests_seconds_bucket[5m]))"\n          }\n        ]\n      },\n      {\n        "title": "JVM Memory",\n        "targets": [\n          {\n            "expr": "jvm_memory_used_bytes{area=\\"heap\\"}"\n          },\n          {\n            "expr": "jvm_memory_max_bytes{area=\\"heap\\"}"\n          }\n        ]\n      },\n      {\n        "title": "GC Activity",\n        "targets": [\n          {\n            "expr": "rate(jvm_gc_pause_seconds_count[5m])"\n          }\n        ]\n      },\n      {\n        "title": "Thread Count",\n        "targets": [\n          {\n            "expr": "jvm_threads_live_threads"\n          }\n        ]\n      },\n      {\n        "title": "Database Connections",\n        "targets": [\n          {\n            "expr": "hikaricp_connections_active"\n          },\n          {\n            "expr": "hikaricp_connections"\n          }\n        ]\n      },\n      {\n        "title": "Top Slow Endpoints",\n        "targets": [\n          {\n            "expr": "topk(10, histogram_quantile(0.95, rate(http_server_requests_seconds_bucket[5m])))"\n          }\n        ]\n      }\n    ]\n  }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"dashboard-drupal",children:"Dashboard Drupal"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-json",metastring:'title="grafana/dashboards/drupal-php.json"',children:'{\n  "dashboard": {\n    "title": "Drupal & PHP-FPM Monitoring",\n    "panels": [\n      {\n        "title": "PHP-FPM Active Processes",\n        "targets": [\n          {\n            "expr": "phpfpm_active_processes"\n          }\n        ]\n      },\n      {\n        "title": "PHP-FPM Pool Usage",\n        "targets": [\n          {\n            "expr": "(phpfpm_active_processes / phpfpm_max_children) * 100"\n          }\n        ]\n      },\n      {\n        "title": "PHP Memory Usage",\n        "targets": [\n          {\n            "expr": "phpfpm_process_last_request_memory"\n          }\n        ]\n      },\n      {\n        "title": "Nginx Request Rate",\n        "targets": [\n          {\n            "expr": "rate(nginx_http_requests_total[5m])"\n          }\n        ]\n      },\n      {\n        "title": "Database Query Time",\n        "targets": [\n          {\n            "expr": "rate(mysql_global_status_queries[5m])"\n          }\n        ]\n      },\n      {\n        "title": "Cache Hit Rate",\n        "targets": [\n          {\n            "expr": "rate(redis_keyspace_hits_total[5m]) / (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m]))"\n          }\n        ]\n      },\n      {\n        "title": "Slow Queries",\n        "targets": [\n          {\n            "expr": "rate(mysql_global_status_slow_queries[5m])"\n          }\n        ]\n      }\n    ]\n  }\n}\n'})}),"\n",(0,r.jsx)(e.h3,{id:"dashboard-angular",children:"Dashboard Angular"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-json",metastring:'title="grafana/dashboards/angular-frontend.json"',children:'{\n  "dashboard": {\n    "title": "Angular Frontend Monitoring",\n    "panels": [\n      {\n        "title": "Page Load Time",\n        "targets": [\n          {\n            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{path=\\"/\\"}[5m]))"\n          }\n        ]\n      },\n      {\n        "title": "API Response Times",\n        "targets": [\n          {\n            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{path=~\\"/api/.*\\"}[5m]))"\n          }\n        ]\n      },\n      {\n        "title": "Error Rate by Status",\n        "targets": [\n          {\n            "expr": "sum by(status) (rate(nginx_http_requests_total{status=~\\"4..|5..\\"}[5m]))"\n          }\n        ]\n      },\n      {\n        "title": "Bandwidth Usage",\n        "targets": [\n          {\n            "expr": "rate(nginx_http_response_size_bytes_sum[5m])"\n          }\n        ]\n      },\n      {\n        "title": "Active Connections",\n        "targets": [\n          {\n            "expr": "nginx_connections_active"\n          }\n        ]\n      },\n      {\n        "title": "Request by Country",\n        "targets": [\n          {\n            "expr": "sum by(country) (rate(nginx_http_requests_total[5m]))"\n          }\n        ]\n      }\n    ]\n  }\n}\n'})}),"\n",(0,r.jsx)(e.p,{children:"Suite dans le prochain fichier... (Dashboard Infrastructure + Int\xe9gration applications)"})]})}function p(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(m,{...n})}):m(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>o,x:()=>i});var t=a(6540);const r={},s=t.createContext(r);function o(n){const e=t.useContext(s);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),t.createElement(s.Provider,{value:e},n.children)}}}]);